--- 
title: "TMA4315: Compulsory exercise 3" 
subtitle: "Group 13: Magnus Liland, Jakob Gerhard Martinussen and Emma Skarstein"
date: "`r format(Sys.time(), '%d.%m.%Y')`" # the current date, can be regular text as well
output: 
  # html_document:
  #   toc: yes
  #   toc_depth: 3
  #   toc_float: yes
  pdf_document:
   toc: false
   toc_depth: 2
---

```{r setup, include = FALSE}
library(formatR)
showsol <- FALSE
library(knitr)
opts_chunk$set(tidy.opts = list(width.cutoff = 68), tidy = TRUE, warning = FALSE, error = FALSE, message = FALSE, echo = TRUE)
```

# The dataset

We will use a *simulated* dataset with clustered data. This data is generated from a fitted model to the `jsp` dataset in the `faraway` R-package.

The following variables are made available:

* `school`: 50 schools, with code 1-50.
* `gender`: A factor with levels boy, girl.
* `social`: Social class of the father, categorical.
    Original class 1-2 = S1, 3-4 = S2, 5-6 = S3 and 7-9 = S4
    Note that these are not ordered and S1 is not necessarily higher or lower class than S2!
* `raven`: Test score (centered around 0).
* `math`: Math score (centered around 0).

We will use `math` as response, and group the data by school.

```{r, echo = TRUE}
dataset <- read.table("https://www.math.ntnu.no/emner/TMA4315/2018h/jsp2.txt", header = TRUE)
```

The number of schools is 49, as we omit school number 43 due to the lack of measurements for our particular subset.

# Analysis

## a) Fitting a linear model

### Visualizing the dataset

First we want to explore the dataset. We will group the data based on `gender` and only include covariates `social`, `raven`, and `math`.

```{r}
library(GGally)
ggpairs(
  data = dataset,
  mapping = aes(col = gender, alpha = 0.7),
  columns = c("social", "raven", "math"),
  legend = 1,
)
```

Some observations can be made:

* A positive correlation can be observed between `raven` and `math` score for both genders, although the correlation is marginally stronger for boys. The Raven test [measures abstract reasoning capabilities](https://en.wikipedia.org/wiki/Raven%27s_Progressive_Matrices), so this makes intuitive sense.
* Girls perform, on average, better than boys on the math test. The weakest math students are mainly boys, and the strongest math students are mainly girls, as well.

### Fitting a linear model


We will now fit a _linear model_ with `math` as response, and `raven` and `gender` as covariates. The model for the $k$th student is therefore

$$
Y_k = {\bf x}_k^\text{T} \pmb{\beta} + \varepsilon_k
$$

where we assume that the $\varepsilon_k$s are independent (between students), and have mean 0 and variance $\sigma^2$ for all students. Some explanations for the terms in the model:

* $Y_k$ is the **predicted** `math` score for student $k$. It is assumed to be normally distributed with mean ${\bf x}_k \pmb \beta$ and variance $\sigma^2$.
* ${\bf x}_k$ is a $3 \times 1$ **covariate vector** for student $k$. For instance, if student $k$ is a boy with `raven` score 5, then ${\bf x}_k = [1, 0, 5]^\text{T}$. Observe that ${\bf x}_{k0}$ is always 0, since this covariate "represents" the intercept of the model.
* $\pmb{\beta}$ is the **regression coefficients** of the fitted model. $\pmb{\beta} = [\beta_{\text{intercept}}, \beta_{\text{raven}}, \beta_{\text{gender}}]^\text{T}$. For example, you would expect a given student to improve their `math` score by $\beta_{\text{raven}}$ if the student improves their `raven` score by one, everything else being equal.
* $\varepsilon_k$ is the **error** in the modelled relationship for student $k$. The important part here is that $\varepsilon_k$ is assumed to be independently and identically distributed with mean $0$ and variance $\sigma^2$ for *all* students.

Now let's estimate the regression coefficients of this linear model and inspect its summary:

```{r}
model <- lm(math ~ raven + gender, data=dataset)
summary(model)
```

The parameter estimates seem to be significant. We have $\beta \approx [-1.3131, 0.1965, 2.5831]^{\text{T}}$. A girl is expected to achieve ~2.5 additional `math` points compared to a boy with the same number of `raven` points. Additionally, a student is expected to score ~0.2 additional `math` points for every `raven` point he or she achieves.

We can rewrite this model as two separate models, one for boys and one for girls, making these relationships clear. For boys

$$
Y_k = 0.1965 \cdot x_{k, \text{raven}} - 1.3131,
$$

and likewise for girls

$$
Y_k = 0.1965 \cdot x_{k, \text{raven}} + 1.225.
$$

Making the statistical advantage of female students apparent.

With this model we investigate how two different factors affect the mathematical capabilities of a student.
The first of these factors is gender. Gender does indeed seem to have a significant effect, as girls seem to achieve better math scores than boys.
Secondly, there is a positive correlation between the performing well on the "Raven" test and the mathematics test. As the Raven test measures abstract, cognitive capabilities, this comes at no large surprise.


---

## b) Fitting a random intercept model

### Explanation of the model

We will now fit a *random intercept model* with `school` as the random intercept. For school $i$ we study the measurement model:

$$
{\bf Y}_{i} = {\bf X}_i\beta + {\bf 1} \gamma_{0i} + \varepsilon_{i}
$$

We denote the number of students in school $i$ as $n_i$, often called a **cluster**.
Here follows some explanations of the different parts of the model:

* ${\bf Y}_{i}$ is the $n_1 \times 1$ **response vector** for school $i$, containing the math scores of each student enrolled in that school.
* ${\bf X}_i$ is the $n_i \times 3$ **design matrix** of the model, containing "population covariates" for each school $i$s student on each row.
* The $3 \times 1$ vector $\beta$ contains the **fixed effects** of the model. These "population effects" are common amongst *all* the schools.
* The $n_1 \times 1$ vector ${\bf 1} \gamma_{0i}$ contains the **random effects** of the model. Specifically in this case, since we have fitted a *random intercept model*, we have a **random intercept** and *no* random slope. ${\bf 1}$ is a $n_i \times 1$ vector containing solely ones, while $\gamma_{0i} \in ℝ$. With other words, ${\bf 1} \gamma_{0i} = [\gamma_{0i}, ..., \gamma_{0i}]^\text{T}$.
* The $n_i \times 1$ vector $\varepsilon_{i}$ contains the **random errors** in the model prediction.


It is important to note that we have made the following distributional assumptions:

* $\gamma_{0i} \sim \text{N}_{1}(0, \tau_0^2)$, where $\tau_0^2$ is a scalar which must be estimated.
* $\varepsilon_{i} \sim \text{N}_{n_i}(0, \sigma^2 I)$, where $\sigma^2$, the variance, also must be estimated.


We have also assumed that there is zero correlation between responses in *different* clusters, and we only have **intraclass correlation**. With other words, $\mathrm{Cov}(Y_{ij}, Y_{kl}) = 0$ for $i \neq k$.


### Fitting the model

We will now fit this model for our dataset using the `lmer` function from the `lem4` R-package, and print a summary of this fitted model:

```{r}
library(lme4)
fitRI1 <- lmer(
    math ~ raven + gender + (1 | school),
    data = dataset,
)
summary(fitRI1)
```

### Comparing the models

We can now compare this *random intercept model* with the *classical linear model* in section a). First observe that $\beta_{\text{raven}}$ has changed from `0.1965` to `0.2144`. The random intercept model has therefore concluded that `raven` score has a even stronger effect upon the `math` score of the pupils. For every additional `raven` score, a student is predicted to score `0.2144` more on the `math` test, everything else being equal.

Also $\beta_{\text{gender}}$ has changed from `2.5381` to `2.5312`. The random intercept model therefore concludes that `gender` has less of an impact on predicted `math` score compared to the classical linear model. The difference is relatively small though, so the models can be said to have similar conclusions regarding gender. A girl is predicted to score `2.5312` more than a boy with the otherwise identical covariate attributes.

### Hypothesis testing

Observe that the output of `summary(fitRI1)` does *not* contain any $p$-values, as we have grown accustomed to with the `lm` and `glm` models. This is intentionally omitted by the `lme4` library authors, as there are a lot of "gotchas" related to the calculation of $p$-values for parameter estimations wrt. linear mixed models.

Quoting ["Fitting Linear Mixed-Effects Models Using lme4"](https://www.jstatsoft.org/index.php/jss/article/view/v067i01/v67i01.pdf) by Bates, Bolker, Mächler and Walker (2015) in Journal of Statistical Software (p. 35):

> While the null distributions (and the sampling distributions of non-null estimates) are asymptotically normal, these distributions are not $t$ distributed for finite size samples – nor are the corresponding null distributions of differences in scaled deviances F distributed.

The $T$-distribution can therefore not be used for a hypothesis test for finite size samples without making a lot of assumptions which might render the conclusion invalid.

A rationalization can also be found the email thread ["lmer, p-values and all that"](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html) written by Douglas Bates, the author of the `lme4` R-package.

We will now ignore all these wise words, arguing that our sample size is large enough and well-behaved, and still calculate a $p$-value for the following hypothesis test.

$$
\mathbf{H}_0: \beta_{\text{raven}} = 0 ~~~\text{vs.}~~~ \mathbf{H}_1: \beta_{\text{raven}} \neq 0
$$

With other words, we want to find out how probable it is that a student's `raven` score has absolutely no effect on the `math` score of the same student. We will perform this test using the *asymptotic* (normal) distribution of $\beta_{\text{raven}}$.

We construct the following test statistic:

$$
z = \frac{\hat{\beta}_{\text{raven}} - 0}{\hat{se}(\beta_{\text{raven}})}
$$

Under the null hypothesis, we assume this test statistic to have a asymptotic standard normal distribution:

$$
Z \sim N_1(0, 1)
$$

We now want to calculate a two-sided $z$-test:

$$
p = 2 \cdot \text{Pr}(Z \geq |z|)
$$

We can calculate the test statistic manually:

```{r}
coefficients <- summary(fitRI1)$coefficients
betaRavenHat <- coefficients[2, 1]
standardErrorRavenHat <- coefficients[2, 2]
ZStatistic <- (betaRavenHat - 0) / standardErrorRavenHat
pValue <- 2 * pnorm(q=abs(ZStatistic), mean=0, sd=0, lower.tail=FALSE)
pValue
```

Or by retrieving the $t$-value directly:

```{r}
tValue <- coefficients[2, 3]
pValue <- 2 * pnorm(q=abs(tValue), mean=0, sd=0, lower.tail=FALSE)
pValue
```

Alternatively, we can use the `lmerTest` R-package which provides $p$-values in the `lmer` summary output:

```{r}
library(lmerTest)
fitRI1Test <- lmer(
    math ~ raven + gender + (1 | school),
    data = dataset,
)
summary(fitRI1Test)
```

All three methods yield the same result, we can relatively confidently assume `raven` scores to have an impact on `math` scores.

We can also construct a $95\%$ confidence interval for the effect of the female gender on the `math` score, using the Wald approximation for fixed effects:

```{r}
confint(fitRI1, method='Wald')[5,]
```

Since the entirety of the $95\%$ confidence interval is contained by $ℝ^+$, we can confidently conclude that girls perform better on the `math` test compared to boys.
